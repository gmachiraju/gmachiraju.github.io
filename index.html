---
layout: default
title: Home
---
<head>
<style>
* {
  box-sizing: border-box;
}

ul li { margin-bottom: 10px; }

.img-container-full {
  float: left;
  width: 100.00%;
  padding: 5px;
}

.img-container-wide {
  float: left;
  width: 50.00%;
  padding: 5px;
}

.img-container {
  float: left;
  width: 25.00%;
  padding: 5px;
}
/*used to say float: left and width: 47*/ 
/*used to center and 88 width*/

.clearfix::after {
  content: "";
  clear: both;
  display: table;
}
</style>
</head>

<!-- ========== BIO ========== -->
<div class="docs-section" id="bio">
  <h4>Bio</h4>
  <p>
  I am a final year PhD Candidate in Biomedical Informatics at Stanford University's department of Biomedical Data Science. My current work centers around developing AI that can expand our understanding of scientific and biomedical data — perhaps to better inform our decision-making (e.g. in the clinic, or for drug development) or perhaps to (re)discover phenomena in high-dimensional unstructured data (e.g. large images, time-series, graphs, or text corpora). We refer to such AI as <b>data copilots</b>. 

  I am extremely fortunate to be advised and mentored by <a href="http://mallicklab.stanford.edu/" target="_blank">Parag Mallick</a> (Radiology) and <a href="https://cs.stanford.edu/~chrismre/" target="_blank">Christopher Ré</a> (Computer Science) and spend much of my time with the <a href="https://hazyresearch.stanford.edu/" target="_blank">Hazy Research group</a> at the <a href="https://ai.stanford.edu/" target="_blank">Stanford AI Lab (SAIL)</a>. My graduate training and research have been graciously funded via the NIH (BD2K, NLM), the Stanford Data Science Institute (<a href="https://datascience.stanford.edu/programs/stanford-data-science-scholars-program" target="_blank">Data Science Scholarship</a>), the International Alliance for Cancer Early Detection (<a href="https://canarycenter.stanford.edu/aced/grants/aced-graduate-fellowship.html" target="_blank">Canary-ACED Graduate Fellowship</a>), and Stanford's <a href="https://hai.stanford.edu/" target="_blank">Institute for Human-Centered Artificial Intelligence (HAI)</a>.
  </p>

  <p>
  <b>I am on the industrial job market</b> for Research Scientist roles, particularly for AI4Science or Responsible AI teams. Please feel free to contact me about opportunities!
  </p>
    <!-- Through my mentors, my work is also generously supported by various agencies and organizations including the DoD, ARL, DARPA, NASA, NIH, Google, -->
  <p> 
    <b>Life bits:</b> On weekends, you can find me and my partner road-tripping to one of California's numerous regional, state, or national parks to spend time on the water and trails. Outside of hiking and camping, my hobbies include painting, gardening, and hosting regular themed dinner and cocktail parties. I also love city trekking with friends and popping into cafés and roasteries, museums, used bookstores (hunting for vintage maths sections), and outdoor pubs with live music sessions. Reach out if you'd like to chat!
  </p>

  <p> 
    <b>As a side note:</b> My name is most similarly pronounced as Batman's city of residence, "Gotham" (i.e. <i>GAW-thum</i>). There are many intonation variants for my Sanskrit-originating name across India, but this pronunciation is the closest to the North Indian variant and is the one I go by. 
    <!-- I also go by "Machi" in some circles. -->
  </p>






<div class="docs-section" id="themes">
  <h4>Research Themes</h4>
    <p>
    <b>My research interests</b> broadly span AI-human collaboration and AI-driven knowledge discovery to expand our understanding of the natural world, particularly for the biological sciences and physical systems. Why? The sciences pose some of the strongest challenges to ML, including high-dimensional unstructured data and uncertain or sparse domain knowledge. These challenges often inspire new paradigms in ML and, in turn, ML for scientific discovery. Methodologically, I currently work at the intersection of:
    <ul>
    <li>Foundation models (FMs) — LLMs, multimodal models, etc.</li>
    <li>(Mechanistic) interpretability & explainability — understanding how models function and make decisions</li>
    <li>Efficient ML for long-range modeling — geometric priors, new forms of convolution, etc.</li>
    </ul> 
  </p>
  <p>
    <b>Questions include:</b> How do FMs work internally? How should we probe them to understand their learning mechanisms? And how do these internals provide advanced generation capability? Can we exploit these internals to create new FM capabilities, either innate or equipped? Can we replicate FM internals cheaply for new model design? 
  </p>
  <p>
    <b>And for science:</b> How do FMs reason over long space- or time-horizons? Can FMs act as “data copilots” to help us understand key actors that distinguish (spatial, temporal, or spatio-temporal) systems from one another? Perhaps to localize binding sites in protein structures (below) or identify cell neighborhoods contributing to aggressive cancers (further below). 
  </p>
   <!-- <br/><br/>
    <br/><br/>
     <br/><br/> -->
  
  <!-- <p style="float: right;"><a href="{{ site.baseurl }}/"><img src='{{ site.baseurl }}{{ site.data.main_info.research_gif }}' height="250" width="250" border="30px"></a></p>
  <p style="float: right;"><a href="{{ site.baseurl }}/"><img src='{{ site.baseurl }}{{ site.data.main_info.cell-graph}}' height="170" width="170" border="50px"></a></p>
     -->
    <div class="clearfix">
      <div class="img-container-full">
          <img src="assets/profile-pics/prospect_prot.png" alt="Proteins" style="width:100%">
      </div>
    </div>

    <!-- <div class="clearfix">
      <div class="img-container-wide">
          <img src="/assets/profile-pics/reg005_montage.png" alt="CODEX" style="width:100%">
      </div>
      <div class="img-container-wide">
          <img src="assets/profile-pics/trip_through_channel_space.gif" alt="Channels" style="width:100%">
      </div>
    </div> -->
</div>




<div class="docs-section" id="research">
  <h4>Thesis Work</h4>
  <p>
   My thesis work primarily focuses on building data copilots to advance cancer subtyping, treatment planning, and prognostics. For deployment, classifying patients (e.g. cancer stage) with high fidelity is important, but also require “evidence” behind that class decision. This ML-generated evidence is known broadly as <b>feature attribution</b> as it can extract <b>class-specific features/regions</b> captured in a datum. My thesis aims include:
    <dl style="PADDING-LEFT: 40px">
    <!-- <dt><b>Designing explainability evaluation frameworks for architectural selection</b></dt> -->
    <dt><b>Evaluating feature attribution given partial contexts</b></dt>
    <dd>In the realm of high-dimensional data, many ML models today are considered “partial-context” since they are limited by how much data they can process at once. Can such models still perform reliable feature attribution? Are some architectures or attribution methods inherently better at detecting class-specific regions? We design an evaluation framework for improved architecture and attribution selection [ECCV 22].</dd>
    <dt><b> </b></dt>
    <dd> </dd>
    <!-- <dt><b>Designing inherently interpretable architectures to mine class-specific regions (i.e. data copilots)</b></dt> -->
    <dt><b>Building performant feature attribution methods for large models & data</b></dt>
    <dd>We reason that feature attribution can be enabled by richer data representations, and thus seek to equip this capability to FMs. To both interface with FMs and operate over high-dimensional unstructured data (e.g. images, graphs, text), we developed interpretable convolutional architectures called "prospector heads" to mine for class-specific regions [ICML 23, arXiv 24].</dd>
    <dt><b> </b></dt>
    <dd> </dd> 
    <!-- <dt><b>Applications in spatial biology for biomarker discovery</b></dt> -->
    <dt><b>Deploying feature attribution for knowledge discovery</b></dt>
    <dd>With FMs and scalable feature attribution, we seek to improve cancer subtyping, treatment planning, and prognostics by discovering novel spatial biomarkers of cancer progression in patient biopsies. To do this, we are building data copilots for single-cell spatial biology, including proteomics datasets provided by GE Global Research.</dd>
    </dl>

    <div class="clearfix">
      <div class="img-container-full">
          <img src="assets/profile-pics/cell-graph.png" alt="Cell graph" style="width:100%">
      </div>
    </div>
</div>





<!-- ========== PUBLICATIONS ========== -->
<div class="docs-section" id="publications">
  <h4>Preprints & Publications</h4>
  <p>While my thesis research focuses on interpretable and explainable AI in the context of high-dimensional biomedical data, I've been privileged to work in several methods and application domains. <u>A copy of my CV can be found at the bottom of this page.</u> <b>Stay tuned for future publications on:</b> 
  <ol>
    <li>Multimodal FMs that pass medical board exams</li>
    <li>Data copilots for spatial biology: <i>in silico</i> discovery of biomarkers of cancer progression</li>
    <li>Review paper: explainable ML for digital pathology & spatial biology</li>
    <li>Characterizing human- and LLM-derived sequential decisions in competitive games like chess</li>
    <li>VLM-driven zero-shot segmentation with long text captions</li>
    <li>Fact-checking multimodal FMs to improve image tagging & retrieval</li>
    <li>Satellite imagery VLMs fine-tuned to predict measures of maternal health & child mortality</li>
    <li>Satellite imagery VLMs fine-tuned for few-shot detection of human labor trafficking encampments in the Amazon Rainforest</li>
  </ol> 

  <br/><br/>Most recent publications on <a href="{{ site.data.main_info.google_scholar }}" target="_blank">Google Scholar</a>.<br/>
  <sup>‡</sup> indicates equal contribution.<br/>
  <sup>§</sup> indicates authorship associated with consortium.
  </p>

  <ul class="tab-nav">
    <li><div class="button active" data-ref="#papers-selected">Selected</div></li>
    <li><div class="button" data-ref="#papers-all">All</div></li>
  </ul>

  <div class="tab-content">
    <div class="tab-pane active" id="papers-selected">
      {% assign selected_papers = site.data.publications.papers | where: "selected", "y" %}
      {% for paper in selected_papers %}
        <div class="paper">
          <p class="title"><b>{{ paper.title }}</b></p>
          <p>{{ paper.authors }}</p>
          <p><i>{{ paper.venue }}</i></p>
           <div class="paper-buttons">
            {% if paper.paper_pdf %}
              <a class="button" href="{{ paper.paper_pdf | prepend: site.baseurl }}" target="_blank">Paper</a>
            {% endif %}

            {% if paper.slides %}
              <a class="button" href="{{ paper.slides | prepend: site.baseurl }}" target="_blank">Slides</a>
            {% endif %}

            {% if paper.poster %}
              <a class="button" href="{{ paper.poster | prepend: site.baseurl }}" target="_blank">Poster</a>
            {% endif %}

            {% if paper.video %}
              <a class="button" href="{{ paper.video }}" target="_blank">Video</a>
            {% endif %}

            {% if paper.code %}
              <a class="button" href="{{ paper.code }}" target="_blank">Code</a>
            {% endif %}
          </div>
        </div>
      {% endfor %}
    </div>

    <div class="tab-pane" id="papers-all">
      {% for paper in site.data.publications.papers %}
        <div class="paper">
          <p class="title"><b>{{ paper.title }}</b></p>
          <p>{{ paper.authors }}</p>
          <p><i>{{ paper.venue }}</i></p>
           <div class="paper-buttons">
            {% if paper.paper_pdf %}
              <a class="button" href="{{ paper.paper_pdf | prepend: site.baseurl }}" target="_blank">Paper</a>
            {% endif %}

            {% if paper.slides %}
              <a class="button" href="{{ paper.slides | prepend: site.baseurl }}" target="_blank">Slides</a>
            {% endif %}

            {% if paper.poster %}
              <a class="button" href="{{ paper.poster | prepend: site.baseurl }}" target="_blank">Poster</a>
            {% endif %}

            {% if paper.video %}
              <a class="button" href="{{ paper.video }}" target="_blank">Video</a>
            {% endif %}

            {% if paper.code %}
              <a class="button" href="{{ paper.code }}" target="_blank">Code</a>
            {% endif %}
          </div>
        </div>
      {% endfor %}
    </div>
  </div>
</div>


<!-- ========== RESUME ========== -->
<div class="docs-section" id="resume">
  <h4>Vitæ</h4>

  <!-- <p>More details (projects, collaborators, talks, academic service, relevant coursework) can be found on my <a href={{ "/assets/cv/CV_stanford_oct22.pdf" | prepend: site.baseurl }} target="_blank">CV</a> (updated Oct 2022) and <a href="https://www.linkedin.com/in/gmachiraju/" target="_blank">LinkedIn page</a>.</p> -->

  <p>More details (projects, collaborators, talks, academic service, relevant coursework) can be found on my <a href="https://drive.google.com/file/d/1fbyMCSCxWadPrmkU58TnrZ7TuznNUu6R/view?usp=sharing" target="_blank">CV</a> and <a href="https://www.linkedin.com/in/gmachiraju/" target="_blank">LinkedIn page</a>.</p>

  <!-- The Timeline -->
  <ul class="timeline">
    {% for exp in site.data.experience.experiences %}
    <li>
      {% if exp.category == "work" %}
      <div class="direction-l">
      {% else %}
      <div class="direction-r">
      {% endif %}
        <div class="flag-wrapper">
          <span class="flag">{{ exp.place }}</span>
          <span class="time-wrapper"><span class="time">{{ exp.time }}</span></span>
        </div>
        <div class="desc"><b>{{ exp.title }}</b> <br/> {{ exp.subtitle }}</div>
      </div>
    </li>
    {% endfor %}
  </ul>
</div>


 <!-- ========== PROJECTS ==========  -->
<div class="docs-section" id="process">
  <h4>Process</h4>
  <p>
    One of my favorite aspects of research is thinking about aesthetic and design when communicating technical ideas. This drive to understand ideas by visually communicating them (often to myself) sparked as a dyslexic Maths undergraduate. Despite my numerous interests in Maths, I struggled to parse and conceptualize blocks of textual abstraction in <a href="https://en.wikipedia.org/wiki/History_of_mathematics#Modern">modern mathematical presentation</a>, typical of standard teaching materials. I thus relied heavily on intuition and visual proofs as mental anchors. Thanks in part to training as a <a href="https://dschool.stanford.edu/classes/creativity-in-research-scholars">CIR Scholar</a> at Stanford's <a href="https://dschool.stanford.edu/">Hasso Plattner Institute of Design</a>, I cartoon-ify almost everything I work on and often spend Friday afternoons reflecting on, mocking up, and refining any discussed concepts.
  </p> 
  <ul class="tab-nav">
    <li><div class="button active" data-ref="#projects-selected">Selected</div></li>
    <li><div class="button" data-ref="#projects-all">All</div></li>
  </ul>

  <div class="tab-content">
    <div class="tab-pane active" id="projects-selected">
      {% assign selected_projects = site.data.projects.projects | where: "selected", "y" %}
      {% for project in selected_projects %}
        {% assign index_modulo = forloop.index0 | modulo:3 %}
        {% if index_modulo == 0 %}
          <div class="row">
        {% endif %}

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="{{ project.url }}">
                    <img src="{{ project.thumbnail }}" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>{{ project.title }}</b> <br/>
                  {{ project.subtitle }}
                </div>

            </div>
          </div>

        {% if index_modulo == 2 %}
          </div>
        {% endif %}
      {% endfor %}
    </div>

    <div class="tab-pane" id="projects-all">
      {% for project in site.data.projects.projects %}
        {% assign index_modulo = forloop.index0 | modulo:3 %}
        {% if index_modulo == 0 %}
          <div class="row">
        {% endif %}

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="{{ project.url }}">
                    <img src="{{ project.thumbnail }}" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>{{ project.title }}</b> <br/>
                  {{ project.subtitle }}
                </div>

            </div>
          </div>

        {% if index_modulo == 2 %}
          </div>
        {% endif %}
      {% endfor %}
    </div>
  </div>

</div>




<!-- <div class="docs-section" id="process">
  <h4>Process</h4>
  <p>
    One of my favorite aspects of research is thinking about aesthetic and design when communicating technical ideas. This drive to understand ideas by visually communicating them (often to myself) sparked as a dyslexic Maths undergraduate. After struggling to parse and conceptualize abstraction in <a href="https://medium.com/thesociablesolipsist/what-is-modern-mathematics-for-the-non-mathematician-4c59981de487">modern mathematical presentation</a>, I relied heavily on intuition and visual proofs as mental anchors. Thanks in part to training as a <a href="https://dschool.stanford.edu/classes/creativity-in-research-scholars">CIRS Scholar</a> at Stanford's <a href="https://dschool.stanford.edu/">Hasso Plattner Institute of Design</a>, I spend Friday afternoons reflecting on discussed concepts and drawing, refining my graphic design skills for research. 
  </p> -->
    <!-- <div class="container">
    <div class="box">
      <img src="https://source.unsplash.com/1000x800">
      <span>CSS</span>
    </div>
    <div class="box">
      <img src="https://source.unsplash.com/1000x802">
      <span>Image</span>
    </div>
    <div class="box">
      <img src="https://source.unsplash.com/1000x804">
      <span>Hover</span>
    </div>
    <div class="box">
      <img src="https://source.unsplash.com/1000x806">
      <span>Effect</span>
    </div>
  </div> -->
<!-- </div> -->


<div class="docs-section" id="template">
    <h4>Acknowledgement</h4>
    This website uses the website design and template by <a href="https://github.com/msaveski/www_personal">Martin Saveski</a>. Some stylisitc alterations were made with inspiration from <a href="https://github.com/thashim/thashim.github.io">Tatsunori Hashimoto</a>.
</div>
