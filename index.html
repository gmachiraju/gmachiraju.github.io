---
layout: default
title: Home
---
<!-- ========== BIO ========== -->
<div class="docs-section" id="bio">
  <h4>Bio</h4>
  <p>
  I am a PhD Candidate in Biomedical Data Science at Stanford University. My research interests are primarily motivated by biomedical applications and broadly span (1) the epirical study of application-driven theoretical questions, (2) developing interpretable machine learning methods, and (3) gaining new insights about biomedicine. I am fortunate to be mentored by <a href="http://mallicklab.stanford.edu/" target="_blank">Parag Mallick</a> (Radiology) and <a href="https://hazyresearch.stanford.edu/" target="_blank">Hazy Research group</a> led by <a href="https://cs.stanford.edu/~chrismre/" target="_blank">Christopher Ré</a> (Computer Science). Much of my graduate training was graciously funded via the NIH (BD2K, NLM) with awarded additional scholarship from the <a href="https://datascience.stanford.edu/programs/stanford-data-science-scholars-program" target="_blank">Stanford Data Science Institute</a>. Our lab's work is generously supported by various agencies and organizations including DARPA, NASA, NIH, Google, Stanford's <a href="https://hai.stanford.edu/" target="_blank">Institute for Human-Centered Artificial Intelligence (HAI)</a>.
  <p>

  <p> 
    Before coming to Stanford for graduate training, I worked with Parag Mallick and <a href="https://louisville.edu/medicine/research/cancer/hbfrie01" target="_blank">Hermann Frieboes</a> at the <a href="https://canarycenter.stanford.edu/" target="_blank">Canary Center at Stanford for Cancer Early Detection</a>. Prior to that, I completed my B.A. in Applied Mathematics and a minor in Bioengineering at University of California, Berkeley. During my time at Cal, I was fortunate to work with <a href="https://ihh.github.io/" target="_blank">Ian Holmes</a> and multiple stellar scientists at Lawrence Berkeley National Lab (LBNL). Outside of research, I am passionate about teaching and mentoring and furthering diversity, equity, and inclusion (DEI) in academia.
  </p>

  <p> 
    On weekends, you can find me road-tripping to one of California's numerous regional, state, or national parks to spend time on the water and trails. My hobbies include running, cycling, hiking, camping, picknicking, and cooking for crowds. I love city trekking with friends and visiting cafés and roasteries, used bookstores (with large maths sections), jazzy cocktail bars, and Irish pubs with live music sessions. Reach out if you'd like to chat!
  </p>

  <p> 
    <b>As a side note:</b> my name is most similarly pronounced as Batman's city of residence, "Gotham" (i.e. <i>GAW-thum</i>). There are many intonation variants for my Sanskrit-originating name across India, but this pronunciation is the closest to the North Indian variant and is the one I go by. 
  </p>


<div class="docs-section" id="research">
  <h4>Research</h4>
  <p>
  Currently, my interests and work spans the areas of: deep learning, weak and/or coarse supervision, alignment and interpretability, computer vision, multi-agent and multi-task learning (and related optimization problems), relational reasoning (e.g. encoding long-range dependencies and context), and concept discovery. Motivations include high-resolution data such as megapixel/multiplexed imagery and highly sampled time-series often found in biomedical settings. A copy of my CV can be found at the bottom of this page.


  One major focus of my research aims to better our understanding of spatial systems and the <i>key actors</i> that distinguish such systems from one another. To this end, my thesis work seeks to extract human-interpretable, differentially expressed salient objects captured in high-resolution megapixel images. Rooted in the paradigm of <b>weak and/or coarse supervision</b> and desire for <b>model interpretability</b>, some broad research themes include:
    <dl style="PADDING-LEFT: 40px">
    <dt><b>Architecture selection driven by interpretability</b></dt>
    <dd>For deployment in human-centered applications, evaluation of classifiers can't be anchored on accurate predictions alone. <i>Weakly supervised Salient Object Detection (wsSOD)</i> asks the question of whether image classifiers can identify truly salient objects that are human-interpretable and differentially expressed (i.e. explanation plausibility). Are some architectures (i.e. model families) inherently better at performing wsSOD and classification alike? Are some architectures more robust to low signal-to-noise ratios — e.g. weaker/coarser labels or lower-resolution inputs — when performing both tasks?</dd>
    <dt><b> </b></dt>
    <dd> </dd>
    <dt><b>Designing inherently interpretable architectures</b></dt>
    <dd>We aim to learn more holistic representations of data inputs for more interpretable model explanations. For megapixel images, this entails bypassing the constraints of weak supervision. We hypothesize that megapixel image classifiers will perform better at both wsSOD and prediction if they are incentivized to learn spatial context and long-range dependencies at multiple scales. We are actively exploring generalizable multi-task and multi-agent frameworks and contrastive objectives through ideas in <i>non-cooperative game theory</i> and <i>geostatistics</i>, respectively.</dd>
    </dl>
    </dl>
  </p>
</div>

<div style="clear: right;">
    <p style="float: right;"><a href="{{ site.baseurl }}/"><img src='{{ site.baseurl }}{{ site.data.main_info.research_gif }}' height="200" width="200" border="30px"></a></p>
    <p><b>Primary applications are in tumor pathology and spatial biology.</b> We seek to improve cancer prognostics by discovering histo-molecular biomarkers of cancer progression in the tumor microenvironment. To do this, we analyze state-of-the-art highly multiplexed immunofluorescence tissue microscopy images (>30 image channels) through amazing collaborations at GE Global Research and Stanford's <a href="https://med.stanford.edu/plevritis.html" target="_blank">Plevritis Lab</a>. In such application and data domains, classifier interpretability is both necessary and enters a new frontier in explanation mapping due to the increased channel dimensionality of multiplexed images. 
  </p>
  <p></p>
  <p>
    <a href="{{ site.baseurl }}/"><img class="u-max-full-width" src='{{ site.baseurl }}{{ site.data.main_info.research_pic }}'></a>
  </p>
  <p></p>
<!--   <p>
    <a href="{{ site.baseurl }}/"><img class="u-max-full-width" src='{{ site.baseurl }}{{ site.data.main_info.research_gif }}'></a>
  </p> -->
</div>


<!-- Model robustness under weak supervision and changes in input resolution. When predictive models are only given weak or coarse labels during training, how weak is too weak? Are -->
<!--  my methods and applications work both sit squarely in the eXplainable Artificial Intelligence (XAI) and Interpretable Machine Learning (IML) research community. -->

<!-- ========== PUBLICATIONS ========== -->
<div class="docs-section" id="publications">
  <h4>Preprints & Publications</h4>
  <p>While my current research focuses on computer vision, I've been privileged to work in several informatics methods (and biomedical application) domains, including: graph representation learning (for small molecule function prediction), ML for large-scale deployment (clinical decision support via the EHR, global health monitoring via satellite imagery), factorization methods (multi-omics & wearables data integration), applied inference (to identify cancer-associated gene enhancers), and mathematical and physics-based modeling (of tumor growth and protein shedding). 
  <br/><br/>Most recent publications on <a href="{{ site.data.main_info.google_scholar }}" target="_blank">Google Scholar</a>.<br/>
  <sup>‡</sup> indicates equal contribution.<br/>
  <sup>§</sup> indicates authorship associated with consortium.
  </p>

  <ul class="tab-nav">
    <li><div class="button active" data-ref="#papers-selected">Selected</div></li>
    <li><div class="button" data-ref="#papers-all">All</div></li>
  </ul>

  <div class="tab-content">
    <div class="tab-pane active" id="papers-selected">
      {% assign selected_papers = site.data.publications.papers | where: "selected", "y" %}
      {% for paper in selected_papers %}
        <div class="paper">
          <p class="title"><b>{{ paper.title }}</b></p>
          <p>{{ paper.authors }}</p>
          <p><i>{{ paper.venue }}</i></p>
           <div class="paper-buttons">
            {% if paper.paper_pdf %}
              <a class="button" href="{{ paper.paper_pdf | prepend: site.baseurl }}" target="_blank">Paper</a>
            {% endif %}

            {% if paper.slides %}
              <a class="button" href="{{ paper.slides | prepend: site.baseurl }}" target="_blank">Slides</a>
            {% endif %}

            {% if paper.poster %}
              <a class="button" href="{{ paper.poster | prepend: site.baseurl }}" target="_blank">Poster</a>
            {% endif %}

            {% if paper.video %}
              <a class="button" href="{{ paper.video }}" target="_blank">Video</a>
            {% endif %}

            {% if paper.code %}
              <a class="button" href="{{ paper.code }}" target="_blank">Code</a>
            {% endif %}
          </div>
        </div>
      {% endfor %}
    </div>

    <div class="tab-pane" id="papers-all">
      {% for paper in site.data.publications.papers %}
        <div class="paper">
          <p class="title"><b>{{ paper.title }}</b></p>
          <p>{{ paper.authors }}</p>
          <p><i>{{ paper.venue }}</i></p>
           <div class="paper-buttons">
            {% if paper.paper_pdf %}
              <a class="button" href="{{ paper.paper_pdf | prepend: site.baseurl }}" target="_blank">Paper</a>
            {% endif %}

            {% if paper.slides %}
              <a class="button" href="{{ paper.slides | prepend: site.baseurl }}" target="_blank">Slides</a>
            {% endif %}

            {% if paper.poster %}
              <a class="button" href="{{ paper.poster | prepend: site.baseurl }}" target="_blank">Poster</a>
            {% endif %}

            {% if paper.video %}
              <a class="button" href="{{ paper.video }}" target="_blank">Video</a>
            {% endif %}

            {% if paper.code %}
              <a class="button" href="{{ paper.code }}" target="_blank">Code</a>
            {% endif %}
          </div>
        </div>
      {% endfor %}
    </div>
  </div>
</div>

<!-- ========== PROJECTS ========== 
<div class="docs-section" id="projects">
  <h4>Projects</h4>

  <ul class="tab-nav">
    <li><div class="button active" data-ref="#projects-selected">Selected</div></li>
    <li><div class="button" data-ref="#projects-all">All</div></li>
  </ul>

  <div class="tab-content">
    <div class="tab-pane active" id="projects-selected">
      {% assign selected_projects = site.data.projects.projects | where: "selected", "y" %}
      {% for project in selected_projects %}
        {% assign index_modulo = forloop.index0 | modulo:3 %}
        {% if index_modulo == 0 %}
          <div class="row">
        {% endif %}

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="{{ project.url }}">
                    <img src="{{ project.thumbnail }}" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>{{ project.title }}</b> <br/>
                  {{ project.subtitle }}
                </div>

            </div>
          </div>

        {% if index_modulo == 2 %}
          </div>
        {% endif %}
      {% endfor %}
    </div>

    <div class="tab-pane" id="projects-all">
      {% for project in site.data.projects.projects %}
        {% assign index_modulo = forloop.index0 | modulo:3 %}
        {% if index_modulo == 0 %}
          <div class="row">
        {% endif %}

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="{{ project.url }}">
                    <img src="{{ project.thumbnail }}" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>{{ project.title }}</b> <br/>
                  {{ project.subtitle }}
                </div>

            </div>
          </div>

        {% if index_modulo == 2 %}
          </div>
        {% endif %}
      {% endfor %}
    </div>
  </div>

</div>
-->

<!-- ========== RESUME ========== -->
<div class="docs-section" id="resume">
  <h4>Vitæ</h4>

  <p>More details (projects, collaborators, talks, academic service, relevant coursework) can be found on my <a href={{ "/assets/cv/CV_stanford_oct22_.pdf" | prepend: site.baseurl }} target="_blank">CV</a> (updated Oct 2022) and <a href="https://www.linkedin.com/in/gmachiraju/" target="_blank">LinkedIn page</a>.</p>

  <!-- The Timeline -->
  <ul class="timeline">
    {% for exp in site.data.experience.experiences %}
    <li>
      {% if exp.category == "work" %}
      <div class="direction-l">
      {% else %}
      <div class="direction-r">
      {% endif %}
        <div class="flag-wrapper">
          <span class="flag">{{ exp.place }}</span>
          <span class="time-wrapper"><span class="time">{{ exp.time }}</span></span>
        </div>
        <div class="desc"><b>{{ exp.title }}</b> <br/> {{ exp.subtitle }}</div>
      </div>
    </li>
    {% endfor %}
  </ul>
</div>


<div class="docs-section" id="template">
    <h4>Acknowledgement</h4>
    This website uses the website design and template by <a href="https://github.com/msaveski/www_personal">Martin Saveski</a>. Some stylisitc alterations were made with inspiration from <a href="https://github.com/thashim/thashim.github.io">Tatsunori Hashimoto</a>.
</div>
